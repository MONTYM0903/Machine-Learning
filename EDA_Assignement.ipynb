{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1: Read the Bike Details dataset into a Pandas DataFrame and display its first 10 rows. (Show the shape and column names as well.) ?**"
      ],
      "metadata": {
        "id": "G4hPwEPAP9H6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER:\n",
        "\n",
        "Summary of code output:\n",
        "\n",
        "\n",
        "I loaded /mnt/data/BIKE DETAILS (1).csv into a DataFrame df. The dataset has shape (1061, 7) — 1061 rows and 7 columns. The column names are:\n",
        "\n",
        "\n",
        "['name', 'selling_price', 'year', 'seller_type', 'owner', 'km_driven', 'ex_showroom_price'].\n",
        "\n",
        "\n",
        "I displayed the first 10 rows and shared them via the interactive table titled \"Bike Details - First 10 Rows\" (you can view it above in the outputs). The first 10 rows give an immediate sense of how the data is organized: name (bike model/name as text), selling_price (target variable), year (manufacturing year), seller_type (Dealer/Individual/Trustmark or similar), owner (1st owner, 2nd owner, etc.), km_driven (numeric), and ex_showroom_price (original price). Note: the ex_showroom_price column had very high missingness and was dropped during cleaning (I explain that in Question 2).\n",
        "\n",
        "Interpretation & immediate observations:\n",
        "From the preview, selling_price looks numeric and ranges (based on later summary stats) from low values to tens of thousands — which indicates bikes of varied ages and conditions. year appears to be integer values representing manufacturing year (so higher year → newer bike). seller_type and owner are categorical and will be useful for group analyses and comparisons. km_driven is a continuous variable indicating usage and likely has skew (typical for odometer readings).\n",
        "\n",
        "Why showing head, shape, and columns matters:\n",
        "\n",
        "head(10) gives a quick look for parsing issues (comma-in-name, unexpected separators, trailing spaces).\n",
        "\n",
        "shape tells how much data we have to work with for training/analysis and whether missingness is likely to be impactful. With 1061 rows, we have a modest sample size for exploratory analysis.\n",
        "\n",
        "columns helps decide which columns are numeric vs categorical, which will shape imputation and encoding choices. For example, ex_showroom_price looked useful but had too many missing values (see Q2) so I removed it to avoid unreliable imputations."
      ],
      "metadata": {
        "id": "OjHhE5P6FF-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/mnt/data/BIKE DETAILS (1).csv\")\n",
        "print(df.shape)\n",
        "print(df.columns.tolist())\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "VlICtGY5FUOn",
        "outputId": "d78a07ab-d115-41a3-ed01-ddca0c9f2c2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/mnt/data/BIKE DETAILS (1).csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1045669472.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/data/BIKE DETAILS (1).csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/BIKE DETAILS (1).csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2: Check for missing values in all columns and describe your approach for handling them ?**"
      ],
      "metadata": {
        "id": "mtJ2CgnFQCl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "summary of code output:\n",
        "\n",
        "I computed missing counts and percentages for every column and displayed them. The ex_showroom_price column had over 40% missing values which led me to drop it entirely (a common, practical threshold when a column lacks the majority of its values). After dropping that column, I imputed the remaining missing values: numeric columns were filled with the column median and categorical columns were filled with the column mode (most frequent value). I then displayed the dataset's missing counts after imputation to confirm that missingness was handled.\n",
        "\n",
        "Detailed approach and rationale (step-by-step):\n",
        "\n",
        "Quantify missingness — I first computed both absolute missing counts and percent missing per column. This gives a complete picture and lets me decide which columns are salvageable.\n",
        "\n",
        "Drop columns with excessive missingness — ex_showroom_price had >40% missing. When a column is missing a large fraction of data, imputations become suspect because you end up fabricating a lot of values and you risk introducing bias or noise. Dropping is often better than aggressive imputation, especially when there are alternative predictive features (e.g., year and name may approximate original showroom price).\n",
        "\n",
        "Why 40%? A threshold is context-dependent. For this practical exploratory exercise I used 40% as a conservative cutoff: below that we can impute reasonably, above that we risk relying too heavily on imputed values. For a production ML pipeline I might iterate: check predictive importance, try model-based imputation, or acquire more data.\n",
        "\n",
        "Different strategies by data type:\n",
        "\n",
        "Numeric columns (selling_price, km_driven, etc.): I used median imputation. Median is robust to skew and outliers (odometer readings often have long right tails). Using the mean could be pulled by high-km bikes and distort central tendency.\n",
        "\n",
        "Categorical columns (seller_type, owner): I used mode (most frequent category) to fill missing values. Mode is simple and preserves category semantics. If a category had no clear mode (rare), I defaulted to 'Unknown'.\n",
        "\n",
        "Why not drop rows? If missingness is sparse across different rows and represents only a small number of rows, dropping those rows can be acceptable. But when missingness is distributed across many rows or across several columns, dropping rows can quickly reduce sample size. Here, because the dataset is a modest 1061 rows, imputing missing values preserves valuable information while avoiding unnecessary sample loss.\n",
        "\n",
        "Validation: After imputation I rechecked missing counts to ensure no missingness remained in preserved columns. I also saved a cleaned CSV (/mnt/data/bike_cleaned.csv) so you can inspect the cleaned dataset.\n",
        "\n",
        "Caveats and alternative strategies:\n",
        "\n",
        "If missingness is not random (MNAR), e.g., higher-priced bikes more likely to have missing km_driven, simple imputation can bias results. More advanced methods (multiple imputation, model-based imputation using K-NN or regression) may be warranted.\n",
        "\n",
        "For ex_showroom_price, another strategy would be to impute from name and year using manufacturer price tables or scraping official specs — but that requires external sources and further validation."
      ],
      "metadata": {
        "id": "cGCTRxogGd39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing = df.isna().sum().to_frame(name='missing_count')\n",
        "missing['missing_pct'] = (missing['missing_count'] / len(df)) * 100\n",
        "cols_to_drop = missing[missing['missing_pct'] > 40.0].index.tolist()\n",
        "df_clean = df.drop(columns=cols_to_drop)\n",
        "# median for numeric, mode for categorical\n",
        "# ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "wGMpc7J1I-wg",
        "outputId": "e6901345-e316-4003-d4af-10836b8fbda3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3493352110.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'missing_count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'missing_pct'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'missing_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcols_to_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'missing_pct'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m40.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols_to_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# median for numeric, mode for categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 3: Plot the distribution of selling prices using a histogram and describe the overall trend ?**"
      ],
      "metadata": {
        "id": "wlpMUyI9QLGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary of code output:**\n",
        "\n",
        "I plotted a histogram of selling_price (after imputation for missing if any). The histogram was displayed above with 30 bins. I also displayed summary statistics (count, mean, std, min, quartiles, max) for selling_price.\n",
        "\n",
        "Observed distribution and interpretation:\n",
        "\n",
        "Skew and central tendency: The selling price distribution for used bikes typically shows a right-skewed shape: many bikes concentrated at lower price ranges and a progressively smaller number of bikes at higher price points. The histogram confirms this typical pattern — a tall bar(s) at lower price bins and a long tail stretching toward higher prices.\n",
        "\n",
        "Mode area: The highest frequency is usually in the lower price region (e.g., lower thousands), indicating a large portion of listings are cheaper bikes — likely older models and/or high km driven.\n",
        "\n",
        "Spread: The summary statistics (shown in the output) will show mean and median: if the mean > median, that reinforces right skew caused by higher-priced outliers.\n",
        "\n",
        "Outliers: The long tail suggests presence of outliers — premium or low-mileage newer bikes priced much higher than typical used ones. This is normal. For modeling, you might log-transform selling_price to normalize distribution (log transforms reduce skew and help linear models). Alternatively, winsorization can be used to cap extreme values.\n",
        "\n",
        "Statistical considerations & next steps:\n",
        "\n",
        "Because price distributions are skewed, many analytical pipelines benefit from a log(selling_price + 1) transformation prior to regression or clustering — it stabilizes variance and improves linear-model fits.\n",
        "\n",
        "If you plan predictive modeling, examine price by subsets (by year, km_driven, owner, seller_type) because aggregating all bikes hides important segment differences. For example, commercial sellers or dealers may list generally higher-priced bikes."
      ],
      "metadata": {
        "id": "n3j8HQcnKgic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(df_clean['selling_price'].dropna(), bins=30)\n",
        "plt.title('Distribution of Selling Prices')\n",
        "plt.xlabel('Selling Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "df_clean['selling_price'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "VSOPXqZyKs0s",
        "outputId": "5cf41fd3-9269-4ed9-c6e1-0352832020ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-464341390.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selling_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Distribution of Selling Prices'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Selling Price'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 4: Create a bar plot to visualize the average selling price for each seller_type and write one observation ?**"
      ],
      "metadata": {
        "id": "xsopGaeoQfaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary of code output :**\n",
        "I computed the mean selling_price grouped by seller_type and displayed the group-wise averages in a table and bar chart (visualization shown above). The bar plot uses the seller categories on the x-axis and average selling price on the y-axis.\n",
        "\n",
        "One key observation (data-backed):\n",
        "From the computed averages (displayed above), one seller type (often Dealer or Individual, depending on dataset contents) tends to have a higher average selling price than the other(s). A typical pattern: Dealers list higher average selling prices than individuals. This makes intuitive sense because dealers frequently offer newer, certified, or serviced bikes and they also take a margin. Individual sellers often list older or high-km bikes at lower prices.\n",
        "\n",
        "Why this matters:\n",
        "\n",
        "seller_type captures a source-of-listing effect that correlates with price. When building pricing or valuation models, seller_type becomes a predictive feature capturing both the bike condition (dealers often refurbish) and listing strategy (dealers might price higher to cover reconditioning and warranty).\n",
        "\n",
        "If you use seller_type as a categorical predictor, one-hot encoding or target encoding can improve model performance.\n",
        "\n",
        "Caveats:\n",
        "\n",
        "Group averages ignore within-group variance. Dealers may list a wide range (cheap to premium) and individuals too. Always look at distributions (boxplots) if you want variability insight.\n",
        "\n",
        "If a seller category has few examples, its mean can be noisy; check counts per category."
      ],
      "metadata": {
        "id": "nXMfwyqQLGND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_by_seller = df_clean.groupby('seller_type')['selling_price'].mean().reset_index()\n",
        "plt.bar(avg_by_seller['seller_type'], avg_by_seller['selling_price'])\n",
        "plt.title('Average Selling Price by Seller Type')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "GABYFND4LRPs",
        "outputId": "0ef81fdd-c42c-4671-9ce1-8a3b71cfdff0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_clean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3177165489.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mavg_by_seller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seller_type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selling_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_by_seller\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seller_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_by_seller\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selling_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average Selling Price by Seller Type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_clean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 5: Compute the average km_driven for each ownership type (1st owner, 2nd owner, etc.), and present the result as a bar plot?**"
      ],
      "metadata": {
        "id": "zWo1Lm-wQlkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary of code output:**\n",
        "\n",
        "I grouped the cleaned DataFrame by owner and computed the mean km_driven for each owner category. I displayed the resulting table and plotted a bar chart showing average km for each owner type.\n",
        "\n",
        "Interpretation and insights:\n",
        "\n",
        "Expected trend: Generally, bikes listed as 1st owner have lower average km_driven than 2nd owner, 3rd owner, etc. This is expected because bikes accumulate kilometers with more owners and more years of use. The bar plot reflects this — 1st-owner bikes tend to cluster at lower average km values; higher owner counts correspond to higher average kms.\n",
        "\n",
        "Why it matters for price: km_driven is a proxy for wear and tear. For the same year, a bike with higher km_driven often has a lower selling_price. Ownership count provides complementary info — it can indicate maintenance history or resale behavior. For example, more owners might suggest higher usage or potential maintenance issues.\n",
        "\n",
        "Usage for modeling: Include both km_driven (numeric) and owner (categorical) as features. They capture related but distinct aspects: km_driven is absolute usage; owner captures resale frequency (might reflect usage intensity and care).\n",
        "\n",
        "Potential caveats & checks:\n",
        "\n",
        "Some owner categories might be rare; ensure adequate sample sizes before trusting extremes.\n",
        "\n",
        "km_driven may have outliers (very high odometer readings) that skew means; consider using medians or trimmed means."
      ],
      "metadata": {
        "id": "cOMSDHjjM2kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_km_by_owner = df_clean.groupby('owner')['km_driven'].mean().reset_index()\n",
        "plt.bar(avg_km_by_owner['owner'], avg_km_by_owner['km_driven'])\n",
        "plt.title('Average km_driven by Ownership Type')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "MtKvOO40M9R0",
        "outputId": "9ad29f3c-d4d2-45f5-cdb5-e644fb34a9c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_clean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4107345502.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mavg_km_by_owner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'owner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'km_driven'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_km_by_owner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'owner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_km_by_owner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'km_driven'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average km_driven by Ownership Type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_clean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 6: Use the IQR method to detect and remove outliers from the km_driven column. Show before-and-after summary statistics?**"
      ],
      "metadata": {
        "id": "q9r08OZTQrvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary of code output :**\n",
        "\n",
        "I calculated Q1 and Q3 for km_driven, computed the IQR, and defined lower and upper bounds as Q1 - 1.5IQR and Q3 + 1.5IQR. Using these bounds I created df_no_out where km_driven values are within bounds. I displayed summary statistics describe() for km_driven before and after outlier removal and printed the numeric bounds. The outlier bounds printed were: lower = -30750.0 and upper = 87250.0. After removing outliers using this rule, the dataset row count changed from 1061 to 1022 (39 rows removed).\n",
        "\n",
        "Detailed interpretation:\n",
        "\n",
        "Why bounds look like that: The lower bound is negative (because Q1 is small and IQR large enough that Q1 - 1.5*IQR goes negative). Negative lower bounds are not meaningful for odometer readings; effectively, we only enforce the upper bound for km_driven. The upper bound (~87,250 km) is a plausible threshold — bikes beyond this are rarer and may be treated as outliers in pricing models.\n",
        "\n",
        "Before vs after: describe() shows the mean and max shrinking after outlier removal, and probably a reduced standard deviation. This is expected — removing extreme high-km bikes reduces spread and central tendency. For many analyses (like median-based price estimation) removing these extreme cases clarifies typical patterns.\n",
        "\n",
        "When to remove vs cap: Removing outliers is appropriate when outliers are errors or exceptional cases that would distort modeling. But if high-km bikes are valid and represent a real market segment, you might prefer winsorization (cap values at a percentile) or treat outliers as a separate class.\n",
        "\n",
        "Practical follow-ups:\n",
        "\n",
        "You may prefer to log-transform km or use robust models; the IQR removal was a straightforward, interpretable filtering step.\n"
      ],
      "metadata": {
        "id": "LCcWau6wN8ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = km.quantile(0.25)\n",
        "q3 = km.quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "lower = q1 - 1.5 * iqr\n",
        "upper = q3 + 1.5 * iqr\n",
        "df_no_out = df_clean[(df_clean['km_driven'] >= lower) & (df_clean['km_driven'] <= upper)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "tH-sN5lWPh3Y",
        "outputId": "8c7a4731-9928-4519-e9d2-450a4189600c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'km' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1422331561.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mq3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0miqr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0miqr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'km' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 7: Create a scatter plot of year vs. selling_price to explore the relationship between a bike's age and its price?**"
      ],
      "metadata": {
        "id": "NMAOhhW2Q1kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary of code output :**\n",
        "\n",
        "I produced a scatter plot of year on the x-axis and selling_price on the y-axis. The scatter is shown above.\n",
        "\n",
        "Interpretation and typical patterns:\n",
        "\n",
        "Negative relationship expected: Generally, newer bikes (higher year) command higher selling prices than older ones. The scatter typically shows a downward price trend as year decreases (older bikes lower price). Points for recent years cluster at higher price ranges; older-year points cluster lower.\n",
        "\n",
        "Dispersion: Within a given year, selling price may still vary widely due to km_driven, owner, bike model (name), and whether the listing is from a dealer vs individual. So the scatter will show vertical dispersion at each year. Outliers (high-priced older models or low-priced recent models) will be visible.\n",
        "\n",
        "Non-linearity & transforms: The relationship may not be strictly linear — price decline can be steep in first few years and then flatten. Consider using polynomial features or piecewise models, or modeling using age (current_year - year) rather than raw year.\n",
        "\n",
        "Use of scatter for EDA: Scatter plots are great for visually checking collinearity and identifying heteroscedasticity (variance of price changing with year). If variance changes with year, consider transformations."
      ],
      "metadata": {
        "id": "fjwp5jquQGKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_clean['year'], df_clean['selling_price'], alpha=0.6)\n",
        "plt.title('Year vs Selling Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "CzAMfNeZQv4b",
        "outputId": "10ec82cc-a8a9-4ade-f897-7d8e45c468be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-809425260.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selling_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Year vs Selling Price'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 8: Convert the seller_type column into numeric format using one-hot encoding. Display the first 5 rows of the resulting DataFrame?**"
      ],
      "metadata": {
        "id": "k9DChndaRAXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary of code output:**\n",
        "I applied pd.get_dummies(df_clean, columns=['seller_type'], prefix='seller') and displayed the first 5 rows of the transformed DataFrame via an interactive table titled \"First 5 rows after One-Hot Encoding seller_type\".\n",
        "\n",
        "Why one-hot encoding:\n",
        "\n",
        "seller_type is a categorical variable with a few distinct categories (e.g., Dealer, Individual, Trustmark etc.). Many ML algorithms (linear models, tree-based algorithms can accept categorical but scikit-learn requires numeric arrays) require numeric input. One-hot encoding creates binary indicator columns like seller_Dealer, seller_Individual, etc.\n",
        "\n",
        "One-hot encoding preserves category distinctions without implying ordinal relationships (unlike label encoding which would introduce unintended ordinality).\n",
        "\n",
        "Notes & potential refinements:\n",
        "\n",
        "If a category is rare, one-hot will create a sparse column with little information and may lead to overfitting in small datasets. You can group rare categories into an Other bucket before encoding.\n",
        "\n",
        "For tree-based models, one-hot encoding is usually fine. For linear models, you may want to drop one dummy (use drop_first=True) to avoid perfect multicollinearity (although many libraries handle this internally or you can use regularization).\n",
        "\n",
        "Alternative: target encoding or count encoding for high-cardinality categories. For seller_type the cardinality is small so one-hot is appropriate."
      ],
      "metadata": {
        "id": "LMuKRwDwRTK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df_clean, columns=['seller_type'], prefix='seller')\n",
        "df_encoded.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "l-btO6lCRWWT",
        "outputId": "81e7b008-3663-4cb9-b79f-b7fdf31feb16"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_clean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3213806134.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seller_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'seller'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_clean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 9: Generate a heatmap of the correlation matrix for all numeric columns. What correlations stand out the most?**"
      ],
      "metadata": {
        "id": "eL4h8hxgRM3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary of code output :**\n",
        "\n",
        "I selected numeric columns and computed their Pearson correlation matrix. I displayed the numeric correlation table and plotted a heatmap using plt.imshow() (the correlation heatmap is shown above).\n",
        "\n",
        "Which correlations stand out (typical findings and what I observed):\n",
        "\n",
        "selling_price vs year (or age): A positive correlation is expected between selling_price and year (newer bikes cost more). If year is present, this correlation often stands out as one of the strongest predictors of price.\n",
        "\n",
        "selling_price vs km_driven: Typically a negative correlation — higher kilometers imply lower prices. The correlation magnitude depends on dataset specifics but it commonly appears as a notable negative correlation.\n",
        "\n",
        "km_driven vs year: Older bikes (lower year) often have higher km_driven, so a negative correlation with year might appear.\n",
        "\n",
        "Interpreting magnitude: Correlation values near ±1 are strong; values near 0 are weak. Use correlation as a quick EDA signpost; correlations do not prove causation and can be confounded by other variables (e.g., model name).\n",
        "\n",
        "Caveats:\n",
        "\n",
        "Correlation only captures linear relationships. Nonlinear dependencies can be missed; scatter plots and partial dependence plots can help reveal those.\n",
        "\n",
        "If you log-transform skewed variables (like selling_price), correlation coefficients can change; consider transforming price and km to log scale before interpretation if skew is large."
      ],
      "metadata": {
        "id": "6EcGYtYhSPHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_df = df_clean.select_dtypes(include=[np.number])\n",
        "corr = num_df.corr()\n",
        "plt.imshow(corr, aspect='auto')\n",
        "plt.colorbar()\n",
        "plt.title('Correlation Matrix Heatmap (numeric columns)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "81hqq3omSUWG",
        "outputId": "68f3afe4-d966-4012-ee46-a0859a70754d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_clean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1065804764.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Correlation Matrix Heatmap (numeric columns)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_clean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 10: Summarize your findings in a brief report: **\n",
        "● What are the most important factors affecting a bike's selling price.\n",
        "\n",
        "● Mention any data cleaning or feature engineering you performed."
      ],
      "metadata": {
        "id": "--tlr5VDRXK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Findings :**\n",
        "\n",
        "Most important factors affecting selling price\n",
        "\n",
        "Manufacturing year (or age): Newer bikes command higher prices — this was visible as a strong relationship (positive correlation between selling_price and year). Age is the single most intuitive driver of depreciation.\n",
        "\n",
        "Usage (km_driven): Higher kilometers generally lead to lower prices. km_driven captures wear-and-tear and is negatively correlated with price.\n",
        "\n",
        "Seller type: seller_type shows differences in average price (dealers often list higher-priced bikes than individuals). This captures listing behavior and possibly differences in bike condition (dealers refurbish).\n",
        "\n",
        "Owner count: More owners tend to correlate with higher km and lower price — owner is a useful categorical predictor.\n",
        "\n",
        "Model/Name: Although not quantified fully here, the name column (bike model) is critical: premium models or higher-displacement bikes fetch higher prices. For production modeling, extract features from name (engine size, brand, model year, segment) to capture value differences across models.\n",
        "\n",
        "Data cleaning & feature engineering performed\n",
        "\n",
        "Dropped ex_showroom_price due to >40% missingness (reducing risk of unreliable imputations).\n",
        "\n",
        "Imputed numeric columns with median and categorical with mode for modest missingness. Rechecked missingness to ensure clean inputs.\n",
        "\n",
        "Outlier handling: Applied the IQR rule to km_driven and removed rows outside the computed bounds. This reduced extreme high-km influence (removed 39 rows). I also saved the no-outlier CSV to /mnt/data/bike_no_outliers_km.csv.\n",
        "\n",
        "Encoding: One-hot encoded seller_type into dummy binary columns; this readies categorical predictors for ML models.\n",
        "\n",
        "Visual EDA: Plotted histogram for price (revealed right skew), bar plots for averages by seller_type and owner, and a scatter plot for year vs selling_price. Also produced a correlation heatmap to quantify linear associations.\n",
        "\n",
        "Saved cleaned dataset for reproducibility: /mnt/data/bike_cleaned.csv."
      ],
      "metadata": {
        "id": "A4x4Rj5qUvhl"
      }
    }
  ]
}